{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Exercise 13.3*\n",
    "\n",
    "#### In Section 13.1 we considered policy parameterizations using the soft-max in action preferences (13.2) with linear action preferences (13.3). For this parameterization,prove that the eligibility vector is: (13.9) using the definitions and elementary calculus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equação 13.2:\n",
    "$\\pi(a|s,\\theta) = \\frac{e^{h(s,a,\\theta)}}{e^{h(s,b,\\theta)}}$\n",
    "\n",
    "Equação 13.3: $h(s,a,\\theta) = \\theta^{T} x(s,a)$\n",
    "\n",
    "TIrando o logaritmo de 13.2 e depois de algumas manipulações:\n",
    "\n",
    "$ln \\pi(a|s,\\theta) = h(s,a,\\theta) - ln \\sum_b e^{h(s,b,\\theta)}$\n",
    "\n",
    "\n",
    "Tirando o gradiente de ambos os lados e passando por mais algumas manipulações:\n",
    "\n",
    "$\\nabla ln \\pi(a|s,\\theta) = \\nabla h(s,a,\\theta) - \\sum_b \\nabla h(s,b,\\theta) \\pi(b|s,\\theta)$\n",
    "\n",
    "Da equação 13.3, a expressão acima fica:\n",
    "\n",
    "$\\nabla ln \\pi(a|s,\\theta) = x(s,a) - \\sum_b \\nabla x(s,b) \\pi(b|s,\\theta)$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
