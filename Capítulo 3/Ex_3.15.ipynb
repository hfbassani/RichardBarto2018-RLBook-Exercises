{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercise 3.15:*\n",
    "\n",
    "**In the gridworld example, rewards are positive for goals, negative for\n",
    "running into the edge of the world, and zero the rest of the time. Are the signs of these\n",
    "rewards important, or only the intervals between them? Prove, using (3.8), that adding a\n",
    "constant c to all the rewards adds a constant, $v_c$ , to the values of all states, and thus\n",
    "does not affect the relative values of any states under any policies. What is $v_c$ in terms\n",
    "of $c$ and $\\gamma$?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Resposta 1:\n",
    "\n",
    "Para a equação (3.8) do livro, se adicionarmos uma constante c para cada recompensa, o valor final ficaria como mostrado na Equação (1).\n",
    "\n",
    "\\begin{equation}\n",
    "\n",
    "    G_t' = \\sum_{k=0}^{\\infty} \\gamma^k (R_{t+k+1}+c).\n",
    "\\end{equation}\n",
    "\n",
    "Assim, pela propriedade distributiva da soma,\n",
    "\n",
    "\\begin{equation}\n",
    "    G_t' = \\sum_{k=0}^{\\infty} \\gamma^k R_{t+k+1}+ \\sum_{k=0}^{\\infty} \\gamma^k c.\n",
    "\\end{equation}\n",
    "\n",
    "Além disso, como $0 < \\gamma < 1$,\n",
    "\n",
    "\\begin{equation}\n",
    "    G_t' = G_t + \\frac{c}{1-\\gamma},\n",
    "\\end{equation}\n",
    "\n",
    "com $v_c = \\frac{c}{1-\\gamma}$.\n",
    "\n",
    "Sendo assim, o valor de $G_t$ muda igualmente para políticas distintas, fazendo com que duas políticas continuem com o mesmo valor relativo ($G^1_{t} - G^2_{t}$) após a adição da constante $c$."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
