{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercise 3.19:*\n",
    "\n",
    "**The value of an action, q⇡ (s, a), depends on the expected next reward and\n",
    "the expected sum of the remaining rewards. Again we can think of this in terms of a\n",
    "small backup diagram, this one rooted at an action (state–action pair) and branching to\n",
    "the possible next states:**\n",
    "\n",
    "![Diagrama](./diag_18.png)\n",
    "\n",
    "**Give the equation corresponding to this intuition and diagram for the action value,\n",
    "q⇡ (s, a), in terms of the expected next reward, Rt+1 , and the expected next state value,\n",
    "v⇡ (St+1 ), given that St = s and At = a. This equation should include an expectation but\n",
    "not one conditioned on following the policy. Then give a second equation, writing out the\n",
    "expected value explicitly in terms of p(s0 , r |s, a) defined by (3.2), such that no expected\n",
    "value notation appears in the equation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Resposta 1:\n",
    "\n",
    "$q_\\pi$ pode ser escrito em função de $v_\\pi$ como mostrado na equação,\n",
    "\n",
    "\\begin{equation}\n",
    "\n",
    "    q_{\\pi} = E[G_{t+1} | S_t = s, A_t = a] = \\sum_{i \\in {1,2,3}} E[r_i+\\gamma s_i' | St = s, A_t = a] = E[r_1+\\gamma s_1' | St = s, A_t = a] + E[r_2+\\gamma s_2' | St = s, A_t = a] + E[r_3+\\gamma s_3' | St = s, A_t = a]\n",
    "\n",
    "\\end{equation}\n",
    "\n",
    "Em termos de $\\pi$, essa equação fica,\n",
    "\n",
    "\\begin{equation}\n",
    "\n",
    "    q_{\\pi} = p(s_1',r_1|s, a) * [r_1 + \\gamma v_pi(s_1')] + p(s_2',r_2|s, a) * [r_2 + \\gamma v_pi(s_2')] + p(s_3',r_3|s, a) * [r_3 + \\gamma v_pi(s_3')] \n",
    "\n",
    "\\end{equation}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
